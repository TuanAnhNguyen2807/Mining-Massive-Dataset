{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week1_ex1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbmY8JdmQYT88UyzTMs41L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TuanAnhNguyen2807/Mining-Massive-Dataset/blob/main/Week1_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wllbCkfKvPrt",
        "outputId": "60daf9e8-65e9-48aa-b079-fe1edf2095d3"
      },
      "source": [
        "!pip install pyspark\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 79kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 23.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=c4bd8033fe17b75a5ed137c310ce1f934cc614efbe0b5bf0bf19770d7575663a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhZKm7huv_hF",
        "outputId": "5af37331-40fb-4d2b-aba3-ca09858dec18"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3__clqFwHhV"
      },
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "import collections\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsD9dHVCwJ1m"
      },
      "source": [
        "file = open(\"drive/MyDrive/BigData/Week1/week1_text1.txt\")\n",
        "data = (''.join(e for e in file.read() if e.isalnum() or e == ' ')).lower().split(' ')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN6cgnSWxOSY"
      },
      "source": [
        "words_counted = SparkContext.getOrCreate(conf=SparkConf().setMaster(\"local\").setAppName(\"word counting\")).parallelize(data).map(lambda word: (word, 1)).reduceByKey(lambda x,y: x+y).collect()\n",
        "words_counted.sort(key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn9JDY_axStd",
        "outputId": "1e3107ff-aee4-482d-f36d-8b9faa4ffdcd"
      },
      "source": [
        "print(\"Tổng số từ trong file là \"+str(sum([i[1] for i in words_counted]))+\" từ\")\n",
        "print(\"Có tổng cộng \"+str(len(words_counted))+\" loại từ\")\n",
        "print(\"Các từ có tần suất xuất hiện trên 10 lần: \")\n",
        "_ = [print(words_counted[i][0]+\":\",words_counted[i][1]) for i in range(0, len(words_counted)) if (words_counted[i][1] > 2)]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tổng số từ trong file là 267 từ\n",
            "Có tổng cộng 147 loại từ\n",
            "Các từ có tần suất xuất hiện trên 10 lần: \n",
            "tôi: 12\n",
            "người: 8\n",
            "của: 7\n",
            "họ: 6\n",
            "ngày: 5\n",
            "nghĩa: 5\n",
            "trang: 5\n",
            "có: 5\n",
            "và: 5\n",
            "chết: 4\n",
            "đang: 4\n",
            "một: 4\n",
            "các: 4\n",
            "mộ: 4\n",
            "thích: 4\n",
            "vì: 3\n",
            "không: 3\n",
            "như: 3\n",
            "ngôi: 3\n",
            "hoa: 3\n",
            "những: 3\n",
            "cười: 3\n",
            "cũng: 3\n",
            "cách: 3\n",
            "nó: 3\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}